# app.py (Backend Server with Chat Memory)

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import google.generativeai as genai
import os
import json
from datetime import datetime
from retrival_pipeline import RAGLawRetrieval
import re
from elasticsearch import Elasticsearch

from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()
app = Flask(__name__, static_folder='static', static_url_path='')
CORS(app)

# Simple list-based chat memory storage
chat_history = []
MAX_MESSAGES = 50  # Maximum number of messages to keep in memory

def add_message_to_history(role, content):
    """Add a message to chat history"""
    message = {
        'role': role,
        'content': content,
        'timestamp': datetime.now().isoformat()
    }
    chat_history.append(message)
    
    # Keep only last MAX_MESSAGES to prevent memory overflow
    if len(chat_history) > MAX_MESSAGES:
        chat_history[:] = chat_history[-MAX_MESSAGES:]
    
    print(f"INFO: Added {role} message to history. Total messages: {len(chat_history)}")

def format_conversation_context(max_messages=10):
    """Format recent messages for context"""
    if not chat_history:
        return ""
    
    # Get last max_messages for context
    recent_messages = chat_history[-max_messages:] if len(chat_history) > max_messages else chat_history
    
    context = "L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán g·∫ßn ƒë√¢y:\n"
    for msg in recent_messages:
        role_display = "Ng∆∞·ªùi d√πng" if msg['role'] == 'user' else "Tr·ª£ l√Ω"
        context += f"{role_display}: {msg['content']}\n"
    context += "\nC√¢u h·ªèi hi·ªán t·∫°i:\n"
    
    return context

def clear_chat_history():
    """Clear all chat history"""
    global chat_history
    chat_history = []
    print("INFO: Chat history cleared")

# os.environ['GOOGLE_API_KEY'] = "AIzaSyC_IGEJNCZJrQanC1eAfiOGSrd0rfU_yHs"

try:
    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')
    genai.configure(api_key=GOOGLE_API_KEY)
    print(f"INFO: Google API Key configured successfully from environment variable (...{GOOGLE_API_KEY[-5:]}).")
except KeyError:
    print("CRITICAL ERROR: GOOGLE_API_KEY environment variable not found.")
    # ƒê·ªÉ server v·∫´n ch·∫°y cho m·ª•c ƒë√≠ch debug giao di·ªán, ta s·∫Ω kh√¥ng exit()

# --- ƒê·ªäNH NGHƒ®A SYSTEM PROMPT ---
SYSTEM_PROMPT = """B·∫°n l√† m·ªôt tr·ª£ l√Ω ph√°p l√Ω. H√£y tr·∫£ l·ªùi to√†n di·ªán c√¢u h·ªèi ph√°p l√Ω sau, ch·ªâ d·ª±a tr√™n c√°c vƒÉn b·∫£n ph√°p l√Ω ƒë∆∞·ª£c cung c·∫•p. 
Khi ng∆∞·ªùi d√πng c·∫ßn t∆∞ v·∫•n , s·ª≠ d·ª•ng tools get_specific_law_article_info ƒë·ªÉ l·∫•y c√°c vƒÉn b·∫£n ph√°p lu·∫≠t li√™n quan, sau ƒë√≥ h√£y x√¢y d·ª•ng c√¢u tr·∫£ l·ªùi b·∫±ng c√°ch suy lu·∫≠n t·ª´ng b∆∞·ªõc theo h∆∞·ªõng d·∫´n.

B·∫°n c√≥ th·ªÉ tham kh·∫£o l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán ƒë·ªÉ hi·ªÉu r√µ h∆°n ng·ªØ c·∫£nh c·ªßa c√¢u h·ªèi hi·ªán t·∫°i.

H∆Ø·ªöNG D·∫™N:
1. **B∆∞·ªõc 1 - X√°c ƒë·ªãnh ƒëi·ªÅu lu·∫≠t √°p d·ª•ng:** Ki·ªÉm tra t·ª´ng vƒÉn b·∫£n ph√°p l√Ω ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ x√°c ƒë·ªãnh nh·ªØng ƒëi·ªÅu lu·∫≠t, kho·∫£n, m·ª•c ho·∫∑c quy ƒë·ªãnh n√†o c√≥ th·ªÉ li√™n quan tr·ª±c ti·∫øp ƒë·∫øn c√¢u h·ªèi.
2. **B∆∞·ªõc 2 - Ph√¢n t√≠ch √°p d·ª•ng:** V·ªõi m·ªói ƒëi·ªÅu lu·∫≠t li√™n quan, h√£y tr√≠ch d·∫´n r√µ n·ªôi dung ph√°p l√Ω v√† gi·∫£i th√≠ch t·∫°i sao v√† b·∫±ng c√°ch n√†o ƒëi·ªÅu ƒë√≥ c√≥ th·ªÉ √°p d·ª•ng ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi.
3. **B∆∞·ªõc 3 - ƒê√°nh gi√° m·ª©c ƒë·ªô ƒë·∫ßy ƒë·ªß c·ªßa th√¥ng tin:** N·∫øu c√°c vƒÉn b·∫£n kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi to√†n di·ªán, h√£y n√™u r√µ h·∫°n ch·∫ø n√†y trong ph√¢n t√≠ch.
4. **B∆∞·ªõc 4 - K·∫øt lu·∫≠n ng·∫Øn g·ªçn:** Sau ph·∫ßn ph√¢n t√≠ch chi ti·∫øt, h√£y ƒë∆∞a ra m·ªôt c√¢u tr·∫£ l·ªùi t√≥m t·∫Øt, s√∫c t√≠ch ƒë·ªÉ t·ªïng h·ª£p l·∫°i n·ªôi dung ch√≠nh v√† ƒë∆∞a ra k·∫øt lu·∫≠n ph√°p l√Ω. 

Y√äU C·∫¶U:
- Sau to√†n b·ªô c√¢u tr·∫£ l·ªùi, ghi ra c√°c link web c·ªßa vƒÉn b·∫£n ph√°p l√Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√¢u tr·∫£ l·ªùi ƒë·ªÉ ng∆∞·ªùi d√πng c√≥ th·ªÉ tra c·ª©u, v·ªõi ƒë·ªãnh d·∫°ng:
  "
  B·∫°n c√≥ th·ªÉ ki·ªÉm tra c√°c vƒÉn b·∫£n ph√°p lu·∫≠t li√™n quan t·∫°i ƒë√¢y:
  + [T√™n vƒÉn b·∫£n]: [Link URL]
  + [T√™n vƒÉn b·∫£n]: [Link URL]
  "
- Kh√¥ng s·ª≠ d·ª•ng b·∫•t k·ª≥ ki·∫øn th·ª©c n√†o n·∫±m ngo√†i c√°c vƒÉn b·∫£n ƒë∆∞·ª£c cung c·∫•p.
- Ph·∫£i tr√≠ch d·∫´n r√µ r√†ng ƒëi·ªÅu lu·∫≠t/kho·∫£n/m·ª•c trong vƒÉn b·∫£n. Khi n√™u t√™n 1 vƒÉn b·∫£n ph√°p lu·∫≠t, 
- Kh√¥ng suy di·ªÖn ho·∫∑c b·ªï sung th√¥ng tin ph√°p l√Ω kh√¥ng c√≥ trong vƒÉn b·∫£n.
- C·∫•u tr√∫c c√¢u tr·∫£ l·ªùi bao g·ªìm c√°c k·∫øt qu·∫£ suy lu·∫≠n t·ª´ c√°c b∆∞·ªõc h∆∞·ªõng d·∫´n, v·ªõi c√°c x√¢y d·ª•ng c√¢u t·ª± nhi√™n, gi·ªëng nh∆∞ ng∆∞·ªùi th·∫≠t gi·∫£i th√≠ch
"""

def setup_es_client():
    CLOUD_ID="Legal_RAG_data:YXNpYS1zb3V0aGVhc3QxLmdjcC5lbGFzdGljLWNsb3VkLmNvbTo0NDMkYWJhZmZjOGQxNjA3NGY0Y2EwMzc4NGFhNDdlMmM1MjckNzg2YjMzY2I1NGFjNDNiZTg1NTljZDgxNTJlODJmNDA="
    
    # Connect to Elasticsearch
    if (os.environ.get('LOCAL_MODE', 'True').lower() in ('true', '1', 'yes')):
        es = Elasticsearch([{'host': os.environ.get('ELASTICSEARCH_HOST', "elasticsearch"), 'port': int(os.environ.get('ELASTICSEARCH_PORT', 9200)), 'scheme': 'http'}])
        print(f"LOCAL_MODE b·∫≠t, k·∫øt n·ªëi v·ªõi elasticsearch local th√†nh c√¥ng v·ªõi {os.environ.get('ELASTICSEARCH_HOST', 'elasticsearch')} , {os.environ.get('ELASTICSEARCH_PORT', '9200')}")
    else:
        es = Elasticsearch(
            cloud_id=CLOUD_ID,
            api_key=("lQRSIZcBDy4SfGpi8c3q", "iKwdTKOvjEz31ahN9r7eug")
        )
        print(f"LOCAL_MODE t·∫Øt, k·∫øt n·ªëi v·ªõi elasticsearch cloud th√†nh c√¥ng v·ªõi {CLOUD_ID}")
    return es

retrieval_flow = RAGLawRetrieval(
    es_client=setup_es_client(),
    embedding_model = 'intfloat/multilingual-e5-small',
    query_process_model='gemini-2.0-flash-lite',
    # es_index='chunks_intfloat_multilingual-e5-small',
)

# --- ƒê·ªäNH NGHƒ®A TOOL (H√†m Python v√† Khai b√°o cho Gemini) ---

def get_law_article_details_implementation(query):
    """
    H√†m n√†y ƒë∆∞·ª£c Gemini g·ªçi th√¥ng qua Tool Calling.
    Hi·ªán t·∫°i, n√≥ gi·∫£ l·∫≠p vi·ªác l·∫•y th√¥ng tin chi ti·∫øt c·ªßa m·ªôt ƒëi·ªÅu lu·∫≠t.
    B·∫†N S·∫º THAY TH·∫æ PH·∫¶N GI·∫¢ L·∫¨P D∆Ø·ªöI ƒê√ÇY B·∫∞NG LOGIC TRUY V·∫§N D·ªÆ LI·ªÜU TH·∫¨T C·ª¶A M√åNH.
    """
    print(f"\nüêç [BACKEND PYTHON - TOOL EXECUTOR]: Tool 'get_law_article_details_implementation' called.")
    print(f"   Parameters received from Gemini: query = {query}'")

    results = retrieval_flow.process_query(query, top_k_categories=2, top_k_chunks=20)
    context = ""
    for chunk in results["final_chunks"]:
        context += f"""
        - VƒÉn b·∫£n: {chunk['doc_title']}, Link vƒÉn b·∫£n:{chunk['doc_link']}, N·ªôi dung: {chunk['content']}
        """

    print(f"   Result from YOUR data query (or simulation): {context}")
    return context

# Khai b√°o Tool cho Gemini (gi·ªØ nguy√™n ph·∫ßn n√†y)
get_law_article_tool_declaration = genai.protos.FunctionDeclaration(
    name="get_specific_law_article_info",
    description="""
    L·∫•y th√¥ng tin chi ti·∫øt c·ªßa c√°c ƒëi·ªÅu lu·∫≠t li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
    , d√πng m·ªçi khi ng∆∞·ªùi d√πng c·∫ßn t∆∞ v·∫•n ·ªü b·∫•t k·ª≥ c√¢u h·ªèi n√†o
    """,
    parameters=genai.protos.Schema(
        type=genai.protos.Type.OBJECT,
        properties={
            "query": genai.protos.Schema(type=genai.protos.Type.STRING, description="C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng"),
        },
        required=["query"]
    )
)
law_tool_definition = genai.protos.Tool(function_declarations=[get_law_article_tool_declaration])

# Kh·ªüi t·∫°o Model Gemini (gi·ªØ nguy√™n)
GEMINI_MODEL = None
MODEL_NAME_TO_USE = "gemini-2.0-flash"
try:
    if 'GOOGLE_API_KEY' in os.environ:
        GEMINI_MODEL = genai.GenerativeModel(
            model_name=MODEL_NAME_TO_USE,
            system_instruction=SYSTEM_PROMPT,
            tools=[law_tool_definition]
        )
        print(f"INFO: Gemini Model '{MODEL_NAME_TO_USE}' initialized successfully.")
    else:
        print("WARNING: Gemini Model NOT initialized because GOOGLE_API_KEY is missing.")
except Exception as e:
    print(f"CRITICAL ERROR: Could not initialize Gemini Model '{MODEL_NAME_TO_USE}': {e}")

# Add this function to your app.py

def remove_duplicate_urls(text):
    """
    Remove duplicate URLs in Markdown links where the URL appears as both text and link
    Example: 
    "[https://example.com](https://example.com)" 
    becomes 
    "https://example.com"
    """
    if not text:
        return text
    
    # Pattern to match Markdown links where URL is duplicated as text and link
    # [URL](URL) -> URL
    markdown_duplicate_pattern = r'\[(https?://[^\]]+)\]\(\1\)'
    
    # Replace duplicated Markdown links with just the URL
    cleaned_text = re.sub(markdown_duplicate_pattern, r'\1', text)
    
    return cleaned_text


# Update your /chat endpoint
@app.route('/chat', methods=['POST'])
def handle_chat_request():
    print("\n--- [BACKEND PYTHON - /chat ENDPOINT]: Received new request ---")
    
    if not GEMINI_MODEL:
        print("ERROR: Gemini Model is not available (likely due to missing API Key).")
        return jsonify({"error": "L·ªói m√°y ch·ªß: Model AI ch∆∞a s·∫µn s√†ng (thi·∫øu API Key?)."}), 500
    
    try:
        data = request.get_json()
        if not data or 'user_message' not in data:
            return jsonify({"error": "Y√™u c·∫ßu kh√¥ng h·ª£p l·ªá: Thi·∫øu 'user_message'."}), 400
        
        user_message = data['user_message']
        print(f"   User message: \"{user_message}\"")
        
        # Get conversation context from chat history
        conversation_context = format_conversation_context()
        
        # Add conversation context to the user message
        contextual_message = conversation_context + user_message
        
        # Add user message to history
        add_message_to_history('user', user_message)
        
        # Kh·ªüi t·∫°o chat session v·ªõi system prompt
        chat_session = GEMINI_MODEL.start_chat(
            enable_automatic_function_calling=False
        )
        
        response = chat_session.send_message(contextual_message)
        
        while True:
            called_function_info = None
            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'function_call') and part.function_call and part.function_call.name:
                        called_function_info = part.function_call
                        break
            
            if called_function_info:
                tool_name = called_function_info.name
                tool_args = dict(called_function_info.args)
                print(f"üß† [GEMINI]: Tool call requested: '{tool_name}' with args: {tool_args}")
                
                if tool_name == "get_specific_law_article_info":
                    # G·ªçi h√†m tri·ªÉn khai tool c·ªßa b·∫°n
                    result_from_your_function = get_law_article_details_implementation(
                        tool_args.get("query")
                    )
                    # G·ª≠i k·∫øt qu·∫£ l·∫°i cho Gemini
                    response = chat_session.send_message(genai.protos.Part(
                        function_response=genai.protos.FunctionResponse(
                            name=tool_name, 
                            response={"content": result_from_your_function}
                        )
                    ))
                else:
                    print(f"WARNING: Gemini requested an unknown tool: '{tool_name}'. Ignoring.")
                    break
            else:
                print("   No (more) tool call requested by Gemini.")
                break
        
        final_text = "".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text') and part.text)
        
        # POST-PROCESSING: Remove duplicate links
        final_text = remove_duplicate_urls(final_text)
        print(f"üßπ [POST-PROCESSING]: Duplicate links removed")
        
        # Add bot response to history
        add_message_to_history('assistant', final_text)
        
        print(f"ü§ñ [BACKEND - FINAL RESPONSE TO CLIENT]: \"{final_text}\"")
        print(f"   Total messages in chat history: {len(chat_history)}")
        
        return jsonify({
            "bot_reply": final_text,
            "message_count": len(chat_history)
        })
        
    except Exception as e:
        print(f"ERROR in /chat: {e}")
        import traceback; traceback.print_exc()
        return jsonify({"error": f"L·ªói m√°y ch·ªß: {str(e)}"}), 500

# Simple endpoint to get chat history
@app.route('/chat/history', methods=['GET'])
def get_chat_history_endpoint():
    try:
        return jsonify({
            "messages": chat_history,
            "total_messages": len(chat_history)
        })
    except Exception as e:
        print(f"ERROR in /chat/history: {e}")
        return jsonify({"error": f"L·ªói m√°y ch·ªß: {str(e)}"}), 500

# Simple endpoint to clear chat history
@app.route('/chat/clear', methods=['POST'])
def clear_chat_history_endpoint():
    try:
        clear_chat_history()
        return jsonify({
            "message": "L·ªãch s·ª≠ tr√≤ chuy·ªán ƒë√£ ƒë∆∞·ª£c x√≥a",
            "total_messages": len(chat_history)
        })
    except Exception as e:
        print(f"ERROR in /chat/clear: {e}")
        return jsonify({"error": f"L·ªói m√°y ch·ªß: {str(e)}"}), 500

# Simple endpoint to get chat statistics
@app.route('/chat/stats', methods=['GET'])
def get_chat_stats():
    try:
        return jsonify({
            "total_messages": len(chat_history),
            "max_messages": MAX_MESSAGES
        })
    except Exception as e:
        print(f"ERROR in /chat/stats: {e}")
        return jsonify({"error": f"L·ªói m√°y ch·ªß: {str(e)}"}), 500

# Serve index.html
@app.route('/')
def serve_index():
    return send_from_directory(app.static_folder, 'index.html')

# Serve JS and CSS
@app.route('/<path:path>')
def serve_static_files(path):
    return send_from_directory(app.static_folder, path)

if __name__ == '__main__':
    print("INFO: Starting Flask backend server with simple list-based chat memory...")
    app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 5000)), debug=False)